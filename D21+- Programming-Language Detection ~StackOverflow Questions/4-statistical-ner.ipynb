{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy NER with Statistical Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x1ebbe65ac40>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x1ebbe62afa0>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x1ebbe767040>)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![](https://spacy.io/pipeline-7a14d4edd18f3edfee8f34393bff2992.svg) \n",
    "\n",
    "### tokenization layer is therefore perma, rest can be customized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x1ebbe767040>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.remove_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x1ebbe65ac40>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x1ebbe62afa0>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching x Index/Entity Parsing Fxn\n",
    "https://spacy.io/usage/training#training-simple-style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import create_patterns #common.py contains the matcher\n",
    "matcher = Matcher(nlp.vocab, validate=True)\n",
    "matcher.add(\"PROG_LANG\", None, *create_patterns()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "golang\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I do code with datastuff using python and golang.\")\n",
    "\n",
    "for idx, start, end in matcher(doc):\n",
    "    print(doc[start:end],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i like python, javascript and golang',\n",
       " {'entities': [(7, 13, 'PROGLANG'),\n",
       "   (15, 25, 'PROGLANG'),\n",
       "   (30, 36, 'PROGLANG')]})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_train_data(doc):\n",
    "    detections = [(doc[start:end].start_char, doc[start:end].end_char, 'PROGLANG') for idx, start, end in matcher(doc)]\n",
    "    return (doc.text, {'entities': detections})\n",
    "\n",
    "parse_train_data(nlp(\"i like python, javascript and golang\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.read_csv(\"../data/have_label.txt\", \n",
    "                  nrows=5_000, \n",
    "                  sep='\\t', \n",
    "                  usecols=['Label', 'Title']))\n",
    "\n",
    "titles = df.loc[lambda d: d['Label'] == 1]['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('How to set up unit testing for Visual Studio C++',\n",
       "  {'entities': [(45, 48, 'PROGLANG')]}),\n",
       " ('How do you pack a visual studio c++ project for release?',\n",
       "  {'entities': [(32, 35, 'PROGLANG')]}),\n",
       " ('How do you get leading wildcard full-text searches to work in SQL Server?',\n",
       "  {'entities': [(62, 65, 'PROGLANG')]})]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA = [parse_train_data(d) for d in nlp.pipe(titles) if len(matcher(d)) == 1]\n",
    "TRAIN_DATA[5:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop (Blank English Model, +NER )\n",
    "\n",
    "https://spacy.io/usage/training#training-simple-style)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blank_nlp(train_data):\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    ner = nlp.create_pipe(\"ner\")\n",
    "    nlp.add_pipe(ner, last=True)\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "    for _, annotations in train_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses at iteration 0 - 2020-02-29 16:13:35.823776 {'ner': 421.81081383064986}\n",
      "Losses at iteration 1 - 2020-02-29 16:13:40.236429 {'ner': 16.171604070858784}\n",
      "Losses at iteration 2 - 2020-02-29 16:13:45.031095 {'ner': 10.869232156674228}\n",
      "Losses at iteration 3 - 2020-02-29 16:13:50.309758 {'ner': 5.347369765463781}\n",
      "Losses at iteration 4 - 2020-02-29 16:13:54.814064 {'ner': 5.267283654703734}\n",
      "Losses at iteration 5 - 2020-02-29 16:13:59.583930 {'ner': 7.034331411273773}\n",
      "Losses at iteration 6 - 2020-02-29 16:14:04.977785 {'ner': 20.55244086534093}\n",
      "Losses at iteration 7 - 2020-02-29 16:14:11.207178 {'ner': 16.854737952514622}\n",
      "Losses at iteration 8 - 2020-02-29 16:14:16.702827 {'ner': 12.846826920458023}\n",
      "Losses at iteration 9 - 2020-02-29 16:14:22.886344 {'ner': 7.316021861073125}\n",
      "Losses at iteration 10 - 2020-02-29 16:14:29.519257 {'ner': 0.20566945497729483}\n",
      "Losses at iteration 11 - 2020-02-29 16:14:36.143884 {'ner': 3.7788202090958585}\n",
      "Losses at iteration 12 - 2020-02-29 16:14:42.415683 {'ner': 7.465032841846728}\n",
      "Losses at iteration 13 - 2020-02-29 16:14:48.875113 {'ner': 2.3451352358449675e-07}\n",
      "Losses at iteration 14 - 2020-02-29 16:14:54.256928 {'ner': 3.7464054022410176e-07}\n",
      "Losses at iteration 15 - 2020-02-29 16:15:00.729210 {'ner': 1.5179423036044701e-05}\n",
      "Losses at iteration 16 - 2020-02-29 16:15:06.206157 {'ner': 5.0365825329424435e-05}\n",
      "Losses at iteration 17 - 2020-02-29 16:15:12.115493 {'ner': 9.695175597872534e-09}\n",
      "Losses at iteration 18 - 2020-02-29 16:15:18.315275 {'ner': 1.2864200256492409e-08}\n",
      "Losses at iteration 19 - 2020-02-29 16:15:24.544488 {'ner': 2.5533360552627274e-08}\n"
     ]
    }
   ],
   "source": [
    "nlp = create_blank_nlp(TRAIN_DATA)\n",
    "optimizer = nlp.begin_training()\n",
    "for i in range(20):\n",
    "    losses = {}\n",
    "    batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "    for batch in batches:\n",
    "        texts, annotations = zip(*batch)\n",
    "        nlp.update(\n",
    "            texts,  # batch of texts\n",
    "            annotations,  # batch of annotations\n",
    "            drop=0.1,  # dropout - make it harder to memorise data\n",
    "            losses=losses,\n",
    "        )\n",
    "    print(f\"Losses at iteration {i} - {dt.datetime.now()} {losses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x13cabd2e8>)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Room for Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"i write code in python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">i write code in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"i write code in python\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">i write code in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       " and go</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"i write code in python and go\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
